# llm-building-using-activeloop
HandsOn LLM applications using LangChain and Deep Lake. Langchain gives developers a set of tools and components to build LLM powered applications.


## Data Points

* The maximum number of tokens the model can process, is determined by the specific implementation of the LLM. Each model has token limit it can take in. Split the text into smaller chunks to handle large inputs.
* Few shot learning is the ability that allows LLMs to learn and genralize from limited examples. Examples can be both hard coded or dynamically selected and can be feeded to the LLM.
* occurrence of hallucinations - models can produce text that appears plausible on the surface but is actually factually incorrect or unrelated to the given input.
* LLMs may exhibit biases originating from their training data, resulting in outputs that can generate undesired outcomes.
* LLM examples include Text Summarization, Text Translation, and Question Answering
* Well-known models like GPT family, LLaMA employ subword level tokenization method. One of the variant used is Byte Pair Encoding (BPE)






 